{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d24afcc-5575-4d95-9018-f8779b1e62f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "259c814e-e097-4c2c-8451-7f1bf2406d8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading a Line Delimetered Json (Each Line Will have complete 1 record ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945dba6e-d16c-422a-9d15-d1c6441d37ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"mode\",\"PERMISSIVE\")\\\n",
    "    .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/line_delimited_json.json\")\n",
    "\n",
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d04b719-ae08-42c2-9628-3e4f213261b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lets read a Json File in Which 1 Record have one Extra column as Gender (for all other record with no  column as Gender it will set NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4063441-e7b1-4cab-af00-c16e04558210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.read.format(\"json\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"mode\",\"PERMISSIVE\")\\\n",
    "  .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/single_file_json_with_extra_fields.json\")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03a4925c-39ea-4cf1-a32a-dd2d57c33a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**.option(\"multiLine\",\"true\") : Lets Try To Read Multi-Line Json **\n",
    "- While Reading a multiline json we have to read it as a list, otherwise it will show only 1st element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d3b2be1-25d6-41de-8431-db696f284614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lets First Try to Read Multi-Line Incorrect JSON (not as a list -OR- not as a list of dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4edf8719-8f25-4eb3-9157-8cba7e7795d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df3 = spark.read.format(\"json\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"multiLine\",\"true\")\\\n",
    "  .option(\"mode\",\"permissive\")\\\n",
    "  .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/multi_line_incorrect_json.json\")\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5be94fb-ebef-4b0a-8b4e-d8a76139edfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "Now lets Try to Read Multi-Line correct JSON (as a list -OR- a list of dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3964e941-a535-4910-9c45-05b6f0e47138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df3 = spark.read.format(\"json\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"multiLine\",\"true\")\\\n",
    "  .option(\"mode\",\"permissive\")\\\n",
    "  .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/multi_line_correct_json.json\")\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6bb803f-c8c8-451c-bba6-f41ec766b520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Handling Corrupted JSON : automatic\n",
    "- It will automatic create \"_corrupt_record\" Column and put corrupt record inside that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fc0103-b0fd-413f-b9e4-bd72e6b734c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df4 = spark.read.format(\"json\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"mode\",\"permissive\")\\\n",
    "  .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/corrupted_json.json\")\n",
    "  \n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8a49d7b-ffba-4ae5-88cb-0d763ce0a665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Now Lets Handle /  FLATTEN - NESTED JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4453339-b69f-4fd1-8d07-2529b28711dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lets first try to Read Nested - JSON Data as a simple Multiline JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47b8e96a-8910-4765-8613-432592c431ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data = spark.read.format(\"json\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"inferSchema\",\"true\")\\\n",
    "  .option(\"multiine\",\"true\")\\\n",
    "  .load(\"/Volumes/workspace/default/rajatlearningdata/PySpark_data/resturant_json_data.json\")\n",
    "\n",
    "resturant_json_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221887ef-6cea-483f-aaa3-f9769ddc35c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "690f313c-a054-49c0-9393-c52c81fec018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Above We can see in Nested JSON, some elements are of \"array\" type (like : restaurant), we will \"explode()\" them  \n",
    "Some Elements are of \"struct\" type (like : R) , we can access them using '.' (dot) operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f5d53c-6203-4605-987a-6cd687b34890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data.select(\"*\",explode(\"restaurants\").alias(\"new_restaurant\")).drop(\"restaurants\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f5462a6-bbef-4e3a-81ee-2d55fbc527bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Above we can see now column \"new_restaurant\" is of struct type , we can access it's element using '.' (dot)\n",
    "- try to fetch re_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36aecb05-3304-4acb-8e08-900bdc6546db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data.select(\"*\",explode(\"restaurants\").alias(\"new_restaurant\")).drop(\"restaurants\").select(\"new_restaurant.restaurant.R.res_id\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2b6ef2e-f3af-4fd7-a651-84031147c260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While using Explode if any Column have null then explode remove that entire column . \"explode()\" won't give us result. We have to Use \" explode_outer() \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f69271c7-2867-4a30-bf64-f77746a3c88d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data.select(\"*\",explode(\"restaurants\").alias(\"new_restaurant\")).drop(\"restaurants\")\\\n",
    "  .select(\"*\",\"new_restaurant.restaurant.R.res_id\",\n",
    "          explode(\"new_restaurant.restaurant.establishment_types\").alias(\"establishment_types_new\")).drop(\"new_restaurant\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc1272a4-55ab-4440-a95d-35c5570f208c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now Lets use explode_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "390b66a5-b7ca-4356-9db0-acde334e9c8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "restaurant_json_data.select(\"*\",explode(\"restaurants\").alias(\"new_restaurant\")).drop(\"restaurants\")\\\n",
    "  .select(\"*\",\"new_restaurant.restaurant.R.res_id\",\n",
    "          explode_outer(\"new_restaurant.restaurant.establishment_types\").alias(\"establishment_types_new\")).drop(\"new_restaurant\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "949dc198-46c9-4682-8060-aeecde224aef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Reading JSON",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
