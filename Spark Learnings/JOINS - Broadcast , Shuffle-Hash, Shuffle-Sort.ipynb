{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "579de7fc-6b14-4f50-a7f8-ddec3b6ae93a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5967e428-54dd-4798-97a2-e73eb8459644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1bf2494-97d1-419f-aff6-c4932022d4dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_data = [\n",
    "    (1, \"Rajat\", \"Hyderabad\", \"2023-01-15\"),\n",
    "    (2, \"Amit\", \"Bangalore\", \"2023-02-10\"),\n",
    "    (3, \"Neha\", \"Pune\", \"2023-03-05\"),\n",
    "    (4, \"Priya\", \"Chennai\", \"2023-01-25\"),\n",
    "    (5, \"Vikas\", \"Delhi\", \"2023-04-12\"),\n",
    "    (6, \"Anita\", \"Mumbai\", \"2023-02-18\"),\n",
    "    (7, \"Suresh\", \"Kolkata\", \"2023-03-30\"),\n",
    "    (8, \"Pooja\", \"Jaipur\", \"2023-05-08\"),\n",
    "    (9, \"Rahul\", \"Noida\", \"2023-06-20\"),\n",
    "    (10, \"Kiran\", \"Vizag\", \"2023-07-01\")\n",
    "]\n",
    "\n",
    "# Column names\n",
    "columns = [\"cust_id\", \"cust_name\", \"city\", \"date_of_joining\"]\n",
    "\n",
    "customer_df = spark.createDataFrame(customer_data,columns)\n",
    "customer_df.show()\n",
    "\n",
    "\n",
    "sales_data = [\n",
    "    (1, 101, 2, \"2023-02-01\"),\n",
    "    (2, 102, 1, \"2023-02-12\"),\n",
    "    (3, 103, 5, \"2023-03-08\"),\n",
    "    (4, 101, 3, \"2023-03-15\"),\n",
    "    (5, 104, 2, \"2023-04-10\"),\n",
    "    (6, 105, 4, \"2023-04-22\"),\n",
    "    (7, 102, 1, \"2023-05-05\"),\n",
    "    (8, 106, 6, \"2023-05-18\"),\n",
    "    (9, 103, 2, \"2023-06-02\"),\n",
    "    (10, 107, 1, \"2023-06-25\")\n",
    "]\n",
    "\n",
    "# Column names\n",
    "sales_columns = [\"cust_id\", \"product_id\", \"quantity\", \"date_of_purchase\"]\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data,sales_columns)\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bffe0403-80b2-473a-b280-623cf1d04202",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Normally Spark Going To Apply Sort merge Join if we use any join\n",
    "- .explain() shows the Execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f53aa0c-f692-402d-844f-c132ee80b609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sort_merge_join_df = customer_df.join(sales_df,customer_df[\"cust_id\"] == sales_df[\"cust_id\"], \"inner\")\n",
    "\n",
    "sort_merge_join_df.show()\n",
    "\n",
    "#sort_merge_join_df.explain()\n",
    "\n",
    "# Here Below It is still applying Broadcast hash JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c0d0ba5-3ad9-42c4-a445-967dc4a14f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Applying Broadcast JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b55d984-8ade-4ea3-bdd7-7b74dd8c01d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "broadcast_join_df = customer_df.join(broadcast(sales_df),customer_df[\"cust_id\"] == sales_df[\"cust_id\"], \"inner\")\n",
    "\n",
    "broadcast_join_df.show()\n",
    "\n",
    "broadcast_join_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a58f69a-5779-42fc-b61c-5af5f1f8974a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "JOINS - Broadcast , Shuffle-Hash, Shuffle-Sort",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
